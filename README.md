<div align="center">
<img width="800" height="300" alt="image" src="https://github.com/user-attachments/assets/0e0d8de6-2264-40bb-afe7-dd57be017b3f" />

# ğŸ¤– DeepFake Detector: AI vs Human  
<br>

ğŸ‘¨â€ğŸ’» [Jeferson Acevedo](https://github.com/Jeferson0809) â€¢  ğŸ‘¨â€ğŸ’» [Samuel Noriega](https://github.com/samdng) â€¢  ğŸ‘¨â€ğŸ’» [Oscar Silva](https://github.com/Oscar-Silva-D)

---

</div>

La creciente sofisticaciÃ³n de los modelos generativos ha dificultado la distinciÃ³n entre imÃ¡genes reales y aquellas creadas mediante Inteligencia Artificial. Esta problemÃ¡tica afecta la veracidad de la informaciÃ³n, la seguridad digital y la confianza en los contenidos visuales que circulan en la web.

Este proyecto busca construir un sistema que pueda distinguir automÃ¡ticamente si una imagen es real o fue generada por IA. Para lograrlo, se entrenaron y compararon diferentes modelos de Deep Learning sobre un conjunto de imÃ¡genes altamente variado.

> ğŸ¯ **Objetivo:** DiseÃ±ar y evaluar modelos capaces de clasificar imÃ¡genes reales vs generadas por IA.

---

## ğŸ§  Enfoques evaluados

1. **ğŸ”¹ Redes Neuronales Profundas (DNN / MLP)**  
   Modelos densos usados como lÃ­nea base.

2. **ğŸ”¹ CNNs diseÃ±adas desde cero**  
   Arquitecturas convolucionales ligeras para extracciÃ³n de patrones espaciales.

3. **ğŸ”¹ Transfer Learning con CNN preentrenada**  
   Se empleÃ³ **ResNet50**, ajustada para distinguir imÃ¡genes reales y sintÃ©ticas.

4. **ğŸ”¹ Autoencoder como extractor de caracterÃ­sticas**  
   Utilizado para generar embeddings, seguido de una capa MLP de clasificaciÃ³n.

---

## ğŸ—‚ï¸ Dataset: AI-Generated-vs-Real-Images (Hemg)

ğŸ”— **HuggingFace Dataset:**  
https://huggingface.co/datasets/Hemg/AI-Generated-vs-Real-Images-Datasets?clone=true

ğŸ“¦ **152,710 imÃ¡genes:**
- ğŸ§ª 81,174 sintÃ©ticas  
- ğŸ“· 71,536 reales  

Este dataset destaca por su **alta variabilidad visual**: fotos reales, ilustraciones, arte digital, escaneos y documentos envejecidos.  
El subconjunto real incluye imÃ¡genes con:

- ğŸŸ¤ DecoloraciÃ³n  
- ğŸ”¥ Quemaduras  
- ğŸ“„ Rasgaduras  
- ğŸï¸ Ruido analÃ³gico  

Estas caracterÃ­sticas obligan a los modelos a ser robustos ante variaciones reales y artefactos generados por IA.

---

## ğŸ“ MÃ©tricas de evaluaciÃ³n

Los modelos se evaluaron usando:

- ğŸ¯ Accuracy  
- ğŸ¯ Precision  
- ğŸ¯ Recall  
- ğŸ“ˆ AUC  

Estas mÃ©tricas miden la capacidad de distinguir entre imÃ¡genes reales y sintÃ©ticas.

---

## ğŸ“Š Resultados del estudio

| **Modelo**              | **Accuracy** | **PrecisiÃ³n** | **Recall** | **AUC**   |
|-------------------------|--------------|----------------|------------|-----------|
| ğŸ”µ **DNN**              | 71.12%       | 71.24%         | 71.30%     | 70.00%    |
| ğŸŸ£ **Vision Transformer** | 73.64%     | 73.64%         | 73.64%     | 82.32%    |
| ğŸŸ  **CNN**              | 62.53%       | 62.36%         | 62.34%     | 60.00%    |
| ğŸ”´ **Transfer Learning (ResNet50)** | 86.61% | 86.95% | 87.00% | 94.40% |
| ğŸŸ¢ **AutoEncoder**      | 82.00%       | 82.00%         | 82.00%     | 89.00%    |

---

## ğŸ—‚ï¸ Estructura del repositorio

### ğŸ“¸ `images/` â€” Resultados por modelo
- **Autoencoder/** â†’ Matriz, reporte y mÃ©tricas.  
- **CNN/** â†’ Accuracy, matriz de confusiÃ³n y reporte.  
- **CNN+Transfer-Learning/** â†’ Resultados del modelo ResNet50.  
- **DNN/** â†’ Curvas, matrices y reportes.  
- **Vision-Transformer/** â†’ MÃ©tricas y visualizaciones del ViT.

### ğŸ§  `models/` â€” Modelos entrenados
- `CNN.keras`  
- `CNNTL.keras`  
- `DNN_model.keras`

### ğŸ““ `notebooks/` â€” Notebooks utilizados
- `Autoencoder.ipynb`  
- `CNN.ipynb`  
- `CNN+transfer-learning.ipynb`  
- `DNN.ipynb`  
- `Vision_Transformer.ipynb`

### ğŸ“„ `README.md`
DocumentaciÃ³n completa del proyecto.

---

## ğŸ–¼ï¸ Ejemplo del dataset

<div align="center">
  
<img width="880" height="440" alt="image" src="https://github.com/user-attachments/assets/0b8eaefd-1059-466c-a0ae-96798a2162e4" />

</div>

---

## ğŸ¬ PresentaciÃ³n del Proyecto

ğŸ“¹ **Video en YouTube:**  
https://www.youtube.com/watch?v=30R0Vg_JfKM

ğŸ–¥ï¸ **Diapositivas en Canva:**  
https://www.canva.com/design/DAG3My3vKXM/2s-gnqmvPG6LM3aHe3lMQQ/edit?utm_content=DAG3My3vKXM&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton

---

## ğŸ Conclusiones

El **Transfer Learning con ResNet50** fue la arquitectura con mejor desempeÃ±o, demostrando gran capacidad para diferenciar imÃ¡genes reales de imÃ¡genes generadas por IA.  
La diversidad del dataset permitiÃ³ evaluar la robustez de cada modelo ante ruido, degradaciÃ³n fÃ­sica y estilos visuales muy variados.

Este proyecto constituye una base para futuros sistemas de **detecciÃ³n de DeepFakes** y herramientas de **verificaciÃ³n digital**.

---
